import kagglehub
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
# Download latest version
path = kagglehub.dataset_download("niharika41298/gym-exercise-data")
file_path = os.path.join(path, "megaGymDataset.csv")  # Replace with the actual filename
df = pd.read_csv(file_path)
print(df.head())

from datetime import time
''' 
Below is our initial concepts of what a user profile would look like and how we would generate it
{
    "age": 30,
    "gender": "male",
    "weight": 220,
    "fitness_level": 2, # scale 1-3? intermediate, beginner, expert
    "equipment_owned": ["dumbbell"],
    "lifting_limitations": ["knees"],
    "goals": "build muscle"
}

# possible random profile
num_profiles = 500

equipment = ["Body Only", "Dumbbell", "Barbell", "Other", "Cable"] # in the future, we need datasets with more equipment
limitations = [""] # this needs worked on, im unsure of how we want to
goals = ["Muscle Gain", "Fat Loss", "Strength Building", "Endurance", "Flexibility", "General Fitness", "Core"]

profiles = {}

# make personal details about person
for i in range(num_profiles):
    age = np.random.randint(18, 60)
    gender = np.random.choice(["male", "female"])
    weight = np.random.randint(120, 300)
    fitness_level = np.random.randint(1, 10)
    equipment_owned = np.random.choice(equipment)
    lifting_limitations = np.random.choice(limitations)
    goal = np.random.choice(goals)
    length = np.random.randint(30, 180)

    profiles[i] = (age, gender, weight, fitness_level, equipment_owned, lifting_limitations, goal)
    # put in workouts randomly selected from final_df thats filtered from lifting_restricted, equipment_owned, and goal. In the future we will include optimal for time, fitness level and bio.
'''

used_exercises = set()
samples = []
sample_per_combo = 25

goals = df['Type'].unique()
muscles = df['BodyPart'].unique()

for goal in goals:
    for muscle in muscles:
        subset = df[
            (df['Type'] == goal) &
            (df['BodyPart'] == muscle)
        ]

        # Filter out exercises already used
        subset = subset[~subset['Title'].isin(used_exercises)]

        if len(subset) == 0:
            print(f"Skipping {goal} + {muscle} — no unique exercises left")
            continue

        n = min(sample_per_combo, len(subset))
        sampled = subset.sample(n=n, random_state=42)

        # Track used exercises
        used_exercises.update(sampled['Title'])
        samples.append(sampled)

final_df = pd.concat(samples).reset_index(drop=True)
print(f"✅ Final dataset size: {len(final_df)}")


csv_path = "/content/fake_fitness_users_with_tone_restrictions.csv"
user_profiles_df = pd.read_csv(csv_path)

user_profiles_df.head()


import random
import builtins
'''
body parts to exercise
exercise_parts = {
    "left_shoulder": ["shoulder", "raises", "press"],
    "right_shoulder": ["shoulder", "raises", "press"],
    "upper_back": ["row", "pull", "deadlift"],
    "lower_back": ["deadlift", "good morning", "superman"],
    "left_leg": ["squat", "lunge", "leg"],
    "right_leg": ["squat", "lunge", "leg"],
    "left_ankle": ["jump", "lunge", "step"],
    "right_ankle": ["jump", "lunge", "step"],
    "left_wrist": ["curl", "push-up"],
    "right_wrist": ["curl", "push-up"],
    "left_foot": ["jump", "step"],
    "right_foot": ["jump", "step"],
    "neck": ["shrug"]
}
'''
goal_to_type = {    'Muscle Gain': 'Strength',
        'muscle gain': 'Strength',
        'gain muscle': 'Strength',
        'fat loss': 'Cardio',
        'lose fat': 'Cardio',
        'strength building': 'Powerlifting',
        'endurance': 'Cardio',
        'flexibility': 'Stretching',
        'general fitness': ['Strength', 'Cardio'],
        'core': ['Strength', 'Cardio', 'Plyometrics'],
        'tone': ['Strength', 'Cardio'],
        'maintain': ['Strength', 'Cardio']
}
goal_durations = {
    "gain muscle": (45, 75),
    "lose fat": (30, 120),
    "tone": (30, 60),
    "maintain": (30, 60),
    "strength": (60, 90),
    "endurance": (60, 120),
    "flexibility": (20, 60),
    "core": (15, 60)
}
def map_goal_to_type(goal):
    goal = goal.strip().lower()

    for key in goal_to_type:
        key_normalized = key.lower()
        if goal in key_normalized or key_normalized in goal:
            mapped = goal_to_type[key]
            return random.choice(mapped) if isinstance(mapped, list) else mapped

    # If no match found, fall back
    return 'Strength'

def divide_duration(duration, num_exercises, min_exercise=2, max_exercise=25):
    range = builtins.range # a bug that set me back my an hour was that somewhere within the code "range" got changed to an int.
    total_units = duration
    min_units = min_exercise
    max_units = max_exercise

    durations = [min_units] * num_exercises
    remaining_units = total_units - (min_units * num_exercises)

    while remaining_units > 0:
        for i in range(num_exercises):
            if durations[i] < max_units and remaining_units > 0:
                durations[i] += 1
                remaining_units -= 1
    return durations

def generate_user_routine(user_row, exercises_df, num_exercises=5):

    goal = user_row['goal'].strip().lower()
    restriction = user_row['restrictions'].lower()
    workout_type = map_goal_to_type(goal)
    # Filter exercises by selected type 
    filtered = exercises_df[exercises_df['Type'] == workout_type]

    # Remove exercises that might conflict with restriction
    if restriction != 'none':
        filtered = filtered[~filtered['BodyPart'].str.lower().str.contains(restriction)]

    # Pick different exercises for each user
    if len(filtered) < num_exercises:
        exercises = filtered['Title'].tolist()
    else:
        exercises = filtered.sample(n=num_exercises)['Title'].tolist()

    low, high = goal_durations.get(goal.strip().lower(), (30, 60))
    duration = random.randrange(low, high + 1, 5)
    durations = divide_duration(duration, len(exercises))

    exercises_with_time = [
        {'exercise': name, 'duration_minutes': time}
        for name, time in zip(exercises, durations)
    ]
    return {
        'name': user_row['name'],
        'goal': goal,
        'workout_type': workout_type,
        'exercises': exercises_with_time,
        'duration': duration
    }

# Apply to first 500 users.
user_routines = [generate_user_routine(row, final_df) for _, row in user_profiles_df.head(500).iterrows()]
for routine in user_routines:
    goal = routine['goal']
    restriction = routine.get('restriction', 'none').lower()
    exercises = routine['exercises']

import tensorflow as tf
import pandas as pd
useable_data = []
for routine in user_routines: # turn our data into readable data by the neural network
    goal = routine['goal']
    exercises = [ex['exercise'].lower() for ex in routine['exercises']]
    duration = routine['duration']
    restriction = user_profiles_df[user_profiles_df['name'] == name]['restrictions'].values[0].lower()

    useable_data.append({
        'goal': goal,
        'restriction': restriction,
        'duration': duration,
        'exercises': exercises
    })
'''
    for ex in exercises:
        useable_data.append({
            'goal': goal.lower(),
            'restriction': restriction,
            'exercise': ex['exercise'].lower(),
            'duration': ex['duration_minutes']
        })

'''
df = pd.DataFrame(useable_data)
print(df.head())


#this took some research on how we need to format our goals and restrictions to exercises that the neural network can understand
#we have to have it grab the string values from goal, restriction, and exercise.
#we use one_hot because they are not ordered in any way
#exercises are multi_hot because of the neural network being a multi-label classifier and picking from them
goal_lookup = tf.keras.layers.StringLookup(output_mode='one_hot')
restriction_lookup = tf.keras.layers.StringLookup(output_mode='one_hot')
exercise_lookup = tf.keras.layers.StringLookup(output_mode='multi_hot')
# take in each unique feature for goal, restriction, and exercises
goal_lookup.adapt(df['goal'])
restriction_lookup.adapt(df['restriction'])
all_exercises = [ex for sublist in df['exercises'] for ex in sublist] # loop through each profile
exercise_lookup.adapt(all_exercises)

# finally encodes it
goal_encoded = goal_lookup(df['goal'].values)
restriction_encoded = restriction_lookup(df['restriction'].values)
exercise_encoded = tf.stack([
    exercise_lookup(ex_list) for ex_list in df['exercises']
])
#verification
# first number should be number of profiles, second should be the amount per category
print("Goal encoded shape:", goal_encoded.shape)
print("Restriction encoded shape:", restriction_encoded.shape)
print("Exercise encoded shape:", exercise_encoded.shape)


#Before duration can effectively be used we need actual data or to find a way to get filtered data.
#Currently, the neural network will use duration to pick exercises that people with similar amount of times have.
#Unfortuntely we did not have enough time to filter through the exercises and group by average time durations.
duration_scaled = df['duration'].values / df['duration'].max() # changes the durations to a value between 0-1
duration_scaled = tf.convert_to_tensor(duration_scaled, dtype=tf.float32) #convert to a format readable by the neural network
duration_scaled = tf.expand_dims(duration_scaled, axis=1) # nn expects a 2d input
#combine it
inputs = tf.concat([
    tf.cast(goal_encoded, tf.float32),
    tf.cast(restriction_encoded, tf.float32),
    duration_scaled
], axis=1)
#input_size is the total size of unique goals, restrictions, and duration
input_size = goal_encoded.shape[1] + restriction_encoded.shape[1] + 1 #+1 for duration

model = tf.keras.Sequential([
    tf.keras.layers.InputLayer(input_shape=(input_size,)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(exercise_lookup.vocabulary_size(), activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(inputs, exercise_encoded, epochs=30, batch_size=32, validation_split=0.1)
model.save("workout_recommender_model.keras")


# because accuracy isnt the best measure of how the model is doing lets have it generate some exercises
def recommend_exercises(goal, restriction, duration, exercise_count=5):
    goal_input = goal_lookup([goal.lower()]) # grab goal, restriction, and duration to then hot code
    restriction_input = restriction_lookup([restriction.lower()])
    duration_input = tf.convert_to_tensor([[duration / max_duration]], dtype=tf.float32)

    input_tensor = tf.concat([ # same as when we initially made the input.
    tf.cast(goal_input, tf.float32), # stack goal, restriction, duration
    tf.cast(restriction_input, tf.float32),
    duration_input
    ], axis=1)

    predictions = model.predict(input_tensor)[0]

    top_indices = tf.argsort(predictions, direction='DESCENDING')[:exercise_count].numpy() # grab the top exercises from the prediction
    exercise_names = exercise_lookup.get_vocabulary()

    return [exercise_names[i] for i in top_indices]

print(recommend_exercises("gain muscle", "none", 45))
